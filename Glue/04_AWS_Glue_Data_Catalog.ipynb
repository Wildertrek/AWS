{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the AWS Glue Data Catalog\n",
    "\n",
    "https://docs.aws.amazon.com/glue/latest/dg/populate-data-catalog.html\n",
    "\n",
    "The AWS Glue Data Catalog contains references to data that is used as sources and targets of your extract, transform, and load (ETL) jobs in AWS Glue. To create your data warehouse or data lake, you must catalog this data. The AWS Glue Data Catalog is an index to the location, schema, and runtime metrics of your data. You use the information in the Data Catalog to create and monitor your ETL jobs. Information in the Data Catalog is stored as metadata tables, where each table specifies a single data store. Typically, you run a crawler to take inventory of the data in your data stores, but there are other ways to add metadata tables into your Data Catalog. For more information, see [Defining Tables in the AWS Glue Data Catalog](https://docs.aws.amazon.com/glue/latest/dg/tables-described.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following workflow diagram shows how AWS Glue crawlers interact with data stores and other elements to populate the Data Catalog.\n",
    "<img src=\"https://docs.aws.amazon.com/glue/latest/dg/images/PopulateCatalog-overview.png\" align=\"left\" alt=\"populate catalog\" width = \"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the general workflow for how a crawler populates the AWS Glue Data Catalog:\n",
    "\n",
    "1. A crawler runs any custom classifiers that you choose to infer the format and schema of your data. You provide the code for custom classifiers, and they run in the order that you specify. The first custom classifier to successfully recognize the structure of your data is used to create a schema. Custom classifiers lower in the list are skipped.\n",
    "\n",
    "2. If no custom classifier matches your data's schema, built-in classifiers try to recognize your data's schema. An example of a built-in classifier is one that recognizes JSON.\n",
    "\n",
    "3. The crawler connects to the data store. Some data stores require connection properties for crawler access.\n",
    "\n",
    "4. The inferred schema is created for your data.\n",
    "\n",
    "5. The crawler writes metadata to the Data Catalog. A table definition contains metadata about the data in your data store. The table is written to a database, which is a container of tables in the Data Catalog. Attributes of a table include classification, which is a label created by the classifier that inferred the table schema.\n",
    "\n",
    "Topics\n",
    "\n",
    "- [Defining a Database in Your Data Catalog](https://docs.aws.amazon.com/glue/latest/dg/define-database.html)\n",
    "- [Defining Tables in the AWS Glue Data Catalog](https://docs.aws.amazon.com/glue/latest/dg/tables-described.html)\n",
    "- [Defining Connections in the AWS Glue Data Catalog](https://docs.aws.amazon.com/glue/latest/dg/populate-add-connection.html)\n",
    "- [Defining Crawlers](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html)\n",
    "- [Adding Classifiers to a Crawler](https://docs.aws.amazon.com/glue/latest/dg/add-classifier.html)\n",
    "- [Working with Data Catalog Settings on the AWS Glue Console](https://docs.aws.amazon.com/glue/latest/dg/console-data-catalog-settings.html)\n",
    "- [Creating Tables, Updating Schema, and Adding New Partitions in the Data Catalog from AWS Glue ETL Jobs](https://docs.aws.amazon.com/glue/latest/dg/update-from-job.html)\n",
    "- [Populating the Data Catalog Using AWS CloudFormation Templates](https://docs.aws.amazon.com/glue/latest/dg/populate-with-cloudformation-templates.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
