{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Certification Program:\n",
    "1. https://aws.amazon.com/training/\n",
    "2. https://www.awseducate.com/\n",
    "3. https://awseducate.qwiklabs.com/\n",
    "4. https://awseducate.qwiklabs.com/catalog\n",
    "\n",
    "## Github\n",
    "https://github.com/awslabs\n",
    "https://github.com/awslabs/amazon-sagemaker-examples\n",
    "\n",
    "\n",
    "\n",
    "## Commercial Training:\n",
    "1. https://www.udemy.com/courses/search/?q=aws&src=sac&kw=AWS\n",
    "2. https://www.udacity.com/courses/all\n",
    "\n",
    "\n",
    "## Conferences:\n",
    "1. https://aws.amazon.com/events/aws-innovate/machine-learning/\n",
    "\n",
    "## Blogs:\n",
    "1. you can run SQL queries from your SageMaker notebooks using Amazon Athena. This blog post walks you through all the steps required to build the data pipeline—from creating a crawler for your data in Amazon S3 and using AWS Glue for data discovery and cataloging, to using Amazon Athena to store and retrieve table metadata, and Amazon SageMaker to query Athena tables. https://aws.amazon.com/blogs/machine-learning/run-sql-queries-from-your-sagemaker-notebooks-using-amazon-athena/\n",
    "\n",
    "2. From the Amazon Science team:\n",
    "https://www.amazon.science/blog/how-sagemakers-algorithms-help-democratize-machine-learning\n",
    "\n",
    "## Sagemaker:\n",
    "\n",
    "***\n",
    "<img src=\"images/Sagemaker_System.png\" align=\"center\" alt=\"Sagemaker System\" width = \"800\">\n",
    "\n",
    "\n",
    "ML Explainability with Amazon SageMaker Debugger\n",
    "Here is the latest on SageMaker (currently available in commercial)\n",
    "https://aws.amazon.com/blogs/machine-learning/ml-explainability-with-amazon-sagemaker-debugger/\n",
    "\n",
    "Amazon Augmented AI (Amazon A2I)\n",
    "\n",
    "Easily implement human review of machine learning predictions\n",
    "https://aws.amazon.com/augmented-ai/\n",
    "\n",
    "One of the better blogs that walks you through “Training Machine Learning Models on Amazon SageMaker: Ephemeral clusters, experiments, visualization and more.”\n",
    "https://towardsdatascience.com/training-machine-learning-models-on-amazon-sagemaker-d95bd089db0d\n",
    "\n",
    "Well-Architected Framework for Machine Learning, this is one of the most comprehensive guides to include MLOps.\n",
    "https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf\n",
    "\n",
    "Meet the Amazon SageMaker team – Ask us about deep learning frameworks or anything related to SageMaker https://sagemakerasktheexperts.splashthat.com/\n",
    "\n",
    "Run RAPIDS experiments at scale using Amazon SageMaker\n",
    "https://medium.com/rapids-ai/running-rapids-experiments-at-scale-using-amazon-sagemaker-d516420f165b\n",
    "RAPIDS container, which the nice people at NVIDIA have already built and pushed to DockerHub (a public repository for containers). The complete example is available on GitHub:https://github.com/shashankprasanna/sagemaker-rapids\n",
    "\n",
    "Amazon Sagemaker Pipe Mode to stream training data directly from S3 storage to training instances, and how this reduces both training time and cost\n",
    "https://medium.com/@julsimon/deep-dive-on-tensorflow-training-with-amazon-sagemaker-and-amazon-s3-12038828075c\n",
    "\n",
    "[Sagemaker Youtube Technical Deep Dive](https://www.youtube.com/watch?v=uQc8Itd4UTs&list=PLhr1KZpdzukcOr_6j_zmSrvYnLUtgqsZz)\n",
    "\n",
    "In this workshop you will build an MLOps pipeline that leverages Amazon SageMaker, a service that supports the whole pipeline of a ML model development, and is the heart of this solution. Around it, you will add different AWS DevOps tools and services to create an automated CI/CD pipeline for the ML model. This pipeline will prepare the data, build your docker images, train and test the ML model, and then integrate the model into a production workload.\n",
    "[OPERATIONALIZING THE MACHINE LEARNING PIPELINE](https://operational-machine-learning-pipeline.workshop.aws/)\n",
    "\n",
    "\n",
    "## EKS:\n",
    "Quick overview of KubeFlow on EKS. Includes section on EKS cluster validation.\n",
    "https://aws.amazon.com/blogs/opensource/kubeflow-amazon-eks/\n",
    "\n",
    "Encrypting Secrets in Amazon EKS\n",
    "Learn how to create Amazon EKS clusters using keys created in either AWS KMS or AWS CloudHSM\n",
    "https://pages.awscloud.com/AWS-Online-Tech-Talks_2020_0502-CON.html?\n",
    "\n",
    "Scaling Machine Learning on Kubernetes and Kubeflow with SageMaker\n",
    "Learn how to do ML experimentation with Kubeflow Pipelines\n",
    "https://pages.awscloud.com/AWS-Online-Tech-Talks_2020_0514-MCL.html\n",
    "\n",
    "eksctl IAM permissions on weaverworks/eksctl \n",
    "https://github.com/weaveworks/eksctl/issues/204\n",
    "\n",
    "Scaling Machine Learning on Kubernetes and Kubeflow with SageMaker\n",
    "https://www.youtube.com/watch?v=LKmkiUdhV58\n",
    "\n",
    "Encrypting Secrets in Amazon EKS\n",
    "https://www.youtube.com/watch?v=d21JrnszG7Y\n",
    "\n",
    "For integrating AWS Secrets Manager with Kubernetes, see\n",
    "https://aws.amazon.com/blogs/containers/aws-secrets-controller-poc/\n",
    "\n",
    "Three day training for EKS\n",
    "https://aws.amazon.com/blogs/containers/learn-how-to-run-containers-on-amazon-elastic-kubernetes-service-with-our-new-instructor-led-course/\n",
    "\n",
    "## EFS\n",
    "Regarding EFS, AWS Lambda support for Amazon Elastic File System now generally available. Elastic persistent file storage for Lambda functions enables entirely new use cases in the ML space. You can now use AWS Lambda to build data-intensive applications, load larger libraries and models, process larger amounts of data in a highly distributed manner, and share data across functions, containers and instances. AWS Lambda will automatically mount the file system and provide a local path to read and write data at low latency. https://aws.amazon.com/about-aws/whats-new/2020/06/aws-lambda-support-for-amazon-elastic-file-system-now-generally-/\n",
    "\n",
    "## Mobile Edge\n",
    "https://aws.amazon.com/greengrass/ml/\n",
    "\n",
    "# Amazon SageMaker Examples\n",
    "https://github.com/aws/amazon-sagemaker-examples\n",
    "\n",
    "This repository contains example notebooks that show how to apply machine learning and deep learning in [Amazon SageMaker](https://aws.amazon.com/sagemaker)\n",
    "\n",
    "## Examples\n",
    "\n",
    "### Introduction to Ground Truth Labeling Jobs\n",
    "\n",
    "These examples provide quick walkthroughs to get you up and running with the labeling job workflow for Amazon SageMaker Ground Truth.\n",
    "\n",
    "- [Bring your own model for sagemaker labeling workflows with active learning](https://github.com/aws/amazon-sagemaker-examples/blob/master/ground_truth_labeling_jobs/bring_your_own_model_for_sagemaker_labeling_workflows_with_active_learning) is an end-to-end example that shows how to bring your custom training, inference logic and active learning to the Amazon SageMaker ecosystem.\n",
    "- [From Unlabeled Data to a Deployed Machine Learning Model: A SageMaker Ground Truth Demonstration for Image Classification](https://github.com/aws/amazon-sagemaker-examples/blob/master/ground_truth_labeling_jobs/from_unlabeled_data_to_deployed_machine_learning_model_ground_truth_demo_image_classification) is an end-to-end example that starts with an unlabeled dataset, labels it using the Ground Truth API, analyzes the results, trains an image classification neural net using the annotated dataset, and finally uses the trained model to perform batch and online inference.\n",
    "- [Ground Truth Object Detection Tutorial](https://github.com/aws/amazon-sagemaker-examples/blob/master/ground_truth_labeling_jobs/ground_truth_object_detection_tutorial) is a similar end-to-end example but for an object detection task.\n",
    "- [Basic Data Analysis of an Image Classification Output Manifest](https://github.com/aws/amazon-sagemaker-examples/blob/master/ground_truth_labeling_jobs/data_analysis_of_ground_truth_image_classification_output) presents charts to visualize the number of annotations for each class, differentiating between human annotations and automatic labels (if your job used auto-labeling). It also displays sample images in each class, and creates a pdf which concisely displays the full results.\n",
    "- [Training a Machine Learning Model Using an Output Manifest](https://github.com/aws/amazon-sagemaker-examples/blob/master/ground_truth_labeling_jobs/object_detection_augmented_manifest_training) introduces the concept of an \"augmented manifest\" and demonstrates that the output file of a labeling job can be immediately used as the input file to train a SageMaker machine learning model.\n",
    "- [Annotation Consolidation](https://github.com/aws/amazon-sagemaker-examples/blob/master/ground_truth_labeling_jobs/annotation_consolidation) demonstrates Amazon SageMaker Ground Truth annotation consolidation techniques for image classification for a completed labeling job.\n",
    "\n",
    "\n",
    "### Introduction to Applying Machine Learning\n",
    "\n",
    "These examples provide a gentle introduction to machine learning concepts as they are applied in practical use cases across a variety of sectors.\n",
    "\n",
    "- [Targeted Direct Marketing](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/xgboost_direct_marketing) predicts potential customers that are most likely to convert based on customer and aggregate level metrics, using Amazon SageMaker's implementation of [XGBoost](https://github.com/dmlc/xgboost).\n",
    "- [Predicting Customer Churn](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/xgboost_customer_churn) uses customer interaction and service usage data to find those most likely to churn, and then walks through the cost/benefit trade-offs of providing retention incentives.  This uses Amazon SageMaker's implementation of [XGBoost](https://github.com/dmlc/xgboost) to create a highly predictive model.\n",
    "- [Time-series Forecasting](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/linear_time_series_forecast) generates a forecast for topline product demand using Amazon SageMaker's Linear Learner algorithm.\n",
    "- [Cancer Prediction](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/breast_cancer_prediction) predicts Breast Cancer based on features derived from images, using SageMaker's Linear Learner.\n",
    "- [Ensembling](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/ensemble_modeling) predicts income using two Amazon SageMaker models to show the advantages in ensembling.\n",
    "- [Video Game Sales](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/video_game_sales) develops a binary prediction model for the success of video games based on review scores.\n",
    "- [MXNet Gluon Recommender System](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/gluon_recommender_system) uses neural network embeddings for non-linear matrix factorization to predict user movie ratings on Amazon digital reviews.\n",
    "- [Fair Linear Learner](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/fair_linear_learner) is an example of an effective way to create fair linear models with respect to sensitive features.\n",
    "- [Population Segmentation of US Census Data using PCA and Kmeans](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/US-census_population_segmentation_PCA_Kmeans) analyzes US census data and reduces dimensionality using PCA then clusters US counties using KMeans to identify segments of similar counties.\n",
    "- [Document Embedding using Object2Vec](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/object2vec_document_embedding) is an example to embed a large collection of documents in a common low-dimensional space, so that the semantic distances between these documents are preserved.\n",
    "- [Traffic violations forecasting using DeepAR](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/deepar_chicago_traffic_violations) is an example to use daily traffic violation data to predict pattern and seasonality to use Amazon DeepAR alogorithm.\n",
    " \n",
    "### SageMaker Automatic Model Tuning\n",
    "\n",
    "These examples introduce SageMaker's hyperparameter tuning functionality which helps deliver the best possible predictions by running a large number of training jobs to determine which hyperparameter values are the most impactful.\n",
    "\n",
    "- [XGBoost Tuning](https://github.com/aws/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/xgboost_direct_marketing) shows how to use SageMaker hyperparameter tuning to improve your model fits for the [Targeted Direct Marketing](introduction_to_applying_machine_learning/xgboost_direct_marketing) task.\n",
    "- [TensorFlow Tuning](https://github.com/aws/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/tensorflow_mnist) shows how to use SageMaker hyperparameter tuning with the pre-built TensorFlow container and MNIST dataset.\n",
    "- [MXNet Tuning](https://github.com/aws/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/mxnet_mnist) shows how to use SageMaker hyperparameter tuning with the pre-built MXNet container and MNIST dataset.\n",
    "- [Keras BYO Tuning](https://github.com/aws/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/keras_bring_your_own) shows how to use SageMaker hyperparameter tuning with a custom container running a Keras convolutional network on CIFAR-10 data.\n",
    "- [R BYO Tuning](https://github.com/aws/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/r_bring_your_own) shows how to use SageMaker hyperparameter tuning with the custom container from the [Bring Your Own R Algorithm](advanced_functionality/r_bring_your_own) example.\n",
    "- [Analyzing Results](https://github.com/aws/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/analyze_results) is a shared notebook that can be used after each of the above notebooks to provide analysis on how training jobs with different hyperparameters performed.\n",
    "\n",
    "### Introduction to Amazon Algorithms\n",
    "\n",
    "These examples provide quick walkthroughs to get you up and running with Amazon SageMaker's custom developed algorithms.  Most of these algorithms can train on distributed hardware, scale incredibly well, and are faster and cheaper than popular alternatives.\n",
    "\n",
    "- [k-means](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/1P_kmeans_highlevel) is our introductory example for Amazon SageMaker.  It walks through the process of clustering MNIST images of handwritten digits using Amazon SageMaker k-means.\n",
    "- [Factorization Machines](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/factorization_machines_mnist) showcases Amazon SageMaker's implementation of the algorithm to predict whether a handwritten digit from the MNIST dataset is a 0 or not using a binary classifier.\n",
    "- [Latent Dirichlet Allocation (LDA)](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/lda_topic_modeling) introduces topic modeling using Amazon SageMaker Latent Dirichlet Allocation (LDA) on a synthetic dataset.\n",
    "- [Linear Learner](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/linear_learner_mnist) predicts whether a handwritten digit from the MNIST dataset is a 0 or not using a binary classifier from Amazon SageMaker Linear Learner.\n",
    "- [Neural Topic Model (NTM)](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/ntm_synthetic) uses Amazon SageMaker Neural Topic Model (NTM) to uncover topics in documents from a synthetic data source, where topic distributions are known.\n",
    "- [Principal Components Analysis (PCA)](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/pca_mnist) uses Amazon SageMaker PCA to calculate eigendigits from MNIST.\n",
    "- [Seq2Seq](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/seq2seq_translation_en-de) uses the Amazon SageMaker Seq2Seq algorithm that's built on top of [Sockeye](https://github.com/awslabs/sockeye), which is a sequence-to-sequence framework for Neural Machine Translation based on MXNet.  Seq2Seq implements state-of-the-art encoder-decoder architectures which can also be used for tasks like Abstractive Summarization in addition to Machine Translation.  This notebook shows translation from English to German text.\n",
    "- [Image Classification](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/imageclassification_caltech) includes full training and transfer learning examples of Amazon SageMaker's Image Classification algorithm.  This uses a ResNet deep convolutional neural network to classify images from the caltech dataset.\n",
    "- [XGBoost for regression](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/xgboost_abalone) predicts the age of abalone ([Abalone dataset](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html)) using regression from Amazon SageMaker's implementation of [XGBoost](https://github.com/dmlc/xgboost).\n",
    "- [XGBoost for multi-class classification](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/xgboost_mnist) uses Amazon SageMaker's implementation of [XGBoost](https://github.com/dmlc/xgboost) to classify handwritten digits from the MNIST dataset as one of the ten digits using a multi-class classifier. Both single machine and distributed use-cases are presented.\n",
    "- [DeepAR for time series forecasting](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/deepar_synthetic) illustrates how to use the Amazon SageMaker DeepAR algorithm for time series forecasting on a synthetically generated data set.\n",
    "- [BlazingText Word2Vec](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/blazingtext_word2vec_text8) generates Word2Vec embeddings from a cleaned text dump of Wikipedia articles using SageMaker's fast and scalable BlazingText implementation.\n",
    "- [Object Detection](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object_detection_pascalvoc_coco) illustrates how to train an object detector using the Amazon SageMaker Object Detection algorithm with different input formats (RecordIO and image).  It uses the Pascal VOC dataset. A third notebook is provided to demonstrate the use of incremental training.\n",
    "- [Object detection for bird images](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object_detection_birds) demonstrates how to use the Amazon SageMaker Object Detection algorithm with a public dataset of Bird images.\n",
    "- [Object2Vec for movie recommendation](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object2vec_movie_recommendation) demonstrates how Object2Vec can be used to model data consisting of pairs of singleton tokens using movie recommendation as a running example.\n",
    "- [Object2Vec for multi-label classification](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object2vec_multilabel_genre_classification) shows how ObjectToVec algorithm can train on data consisting of pairs of sequences and singleton tokens using the setting of genre prediction of movies based on their plot descriptions.\n",
    "- [Object2Vec for sentence similarity](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object2vec_sentence_similarity) explains how to train Object2Vec using sequence pairs as input using sentence similarity analysis as the application.\n",
    "- [IP Insights for suspicious logins](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/ipinsights_login) shows how to train IP Insights on a login events for a web server to identify suspicious login attempts.\n",
    "- [Semantic Segmentation](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/semantic_segmentation_pascalvoc) shows how to train a semantic segmentation algorithm using the Amazon SageMaker Semantic Segmentation algorithm. It also demonstrates how to host the model and produce segmentaion masks and probability of segmentation.\n",
    "\n",
    "### Amazon SageMaker RL\n",
    "\n",
    "The following provide examples demonstrating different capabilities of Amazon SageMaker RL.\n",
    "\n",
    "- [Cartpole using Coach](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_cartpole_coach) demonstrates the simplest usecase of Amazon SageMaker RL using Intel's RL Coach.\n",
    "- [AWS DeepRacer](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_deepracer_robomaker_coach_gazebo) demonstrates AWS DeepRacer trainig using RL Coach in the Gazebo environment.\n",
    "- [HVAC using EnergyPlus](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_hvac_coach_energyplus) demonstrates the training of HVAC systems using the EnergyPlus environment.\n",
    "- [Knapsack Problem](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_knapsack_coach_custom) demonstrates how to solve the knapsack problem using a custom environment.\n",
    "- [Mountain Car](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_mountain_car_coach_gymEnv) Mountain car is a classic RL problem. This notebook explains how to solve this using the OpenAI Gym environment.\n",
    "- [Distributed Neural Network Compression](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_network_compression_ray_custom) This notebook explains how to compress ResNets using RL, using a custom environment and the RLLib toolkit.\n",
    "- [Turtlebot Tracker](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_objecttracker_robomaker_coach_gazebo) This notebook demonstrates object tracking using AWS Robomaker and RL Coach in the Gazebo environment.\n",
    "- [Portfolio Management](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_portfolio_management_coach_customEnv) This notebook uses a custom Gym environment to manage multiple financial investments.\n",
    "- [Autoscaling](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_predictive_autoscaling_coach_customEnv) demonstrates how to adjust load depending on demand. This uses RL Coach and a custom environment.\n",
    "- [Roboschool](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_roboschool_ray) is an open source physics simulator that is commonly used to train RL policies for robotic systems. This notebook demonstrates training a few agents using it.\n",
    "- [Stable Baselines](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_roboschool_stable_baselines) In this notebook example, we will make the HalfCheetah agent learn to walk using the stable-baselines, which are a set of improved implementations of Reinforcement Learning (RL) algorithms based on OpenAI Baselines.\n",
    "- [Travelling Salesman](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_traveling_salesman_vehicle_routing_coach) is a classic NP hard problem, which this notebook solves with AWS SageMaker RL.\n",
    "- [Tic-tac-toe](https://github.com/aws/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_tic_tac_toe_coach_customEnv) is a simple implementation of a custom Gym environment to train and deploy an RL agent in Coach that then plays tic-tac-toe interactively in a Jupyter Notebook.\n",
    "\n",
    "### Scientific Details of Algorithms\n",
    "\n",
    "These examples provide more thorough mathematical treatment on a select group of algorithms.\n",
    "\n",
    "- [Streaming Median](https://github.com/aws/amazon-sagemaker-examples/blob/master/scientific_details_of_algorithms/streaming_median) sequentially introduces concepts used in streaming algorithms, which many SageMaker algorithms rely on to deliver speed and scalability.\n",
    "- [Latent Dirichlet Allocation (LDA)](scientific_details_of_algorithms/lda_topic_modeling) dives into Amazon SageMaker's spectral decomposition approach to LDA.\n",
    "- [Linear Learner features](https://github.com/aws/amazon-sagemaker-examples/blob/master/scientific_details_of_algorithms/linear_learner_class_weights_loss_functions) shows how to use the class weights and loss functions features of the SageMaker Linear Learner algorithm to improve performance on a credit card fraud prediction task\n",
    "\n",
    "### Amazon SageMaker Debugger\n",
    "These examples provide and introduction to SageMaker Debugger which allows debugging and monitoring capabilities for training of machine learning and deep learning algorithms. Note that although these notebooks focus on a specific framework, the same approach works with all the frameworks that Amazon SageMaker Debugger supports. The notebooks below are listed in the order in which we recommend you review them.\n",
    "\n",
    "- [Using a built-in rule with TensorFlow](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-debugger/tensorflow_builtin_rule/)\n",
    "- [Using a custom rule with TensorFlow Keras](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-debugger/tensorflow_keras_custom_rule/)\n",
    "- [Interactive tensor analysis in notebook with MXNet](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-debugger/mnist_tensor_analysis/)\n",
    "- [Visualizing Debugging Tensors of MXNet training](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-debugger/mnist_tensor_plot/)\n",
    "- [Real-time analysis in notebook with MXNet](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-debugger/mxnet_realtime_analysis/)\n",
    "- [Using a built in rule with XGBoost](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-debugger/xgboost_builtin_rules/)\n",
    "- [Real-time analysis in notebook with XGBoost](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-debugger/xgboost_realtime_analysis/)\n",
    "- [Using SageMaker Debugger with Managed Spot Training and MXNet](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-debugger/mxnet_spot_training/)\n",
    "- [Reacting to CloudWatch Events from Rules to take an action based on status with TensorFlow](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-debugger/tensorflow_action_on_rule/)\n",
    "- [Using SageMaker Debugger with a custom PyTorch container](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-debugger/pytorch_custom_container/)\n",
    "\n",
    "### Advanced Amazon SageMaker Functionality\n",
    "\n",
    "These examples that showcase unique functionality available in Amazon SageMaker.  They cover a broad range of topics and will utilize a variety of methods, but aim to provide the user with sufficient insight or inspiration to develop within Amazon SageMaker.\n",
    "\n",
    "- [Data Distribution Types](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/data_distribution_types) showcases the difference between two methods for sending data from S3 to Amazon SageMaker Training instances.  This has particular implication for scalability and accuracy of distributed training.\n",
    "- [Encrypting Your Data](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/handling_kms_encrypted_data) shows how to use Server Side KMS encrypted data with Amazon SageMaker training. The IAM role used for S3 access needs to have permissions to encrypt and decrypt data with the KMS key.\n",
    "- [Using Parquet Data](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/parquet_to_recordio_protobuf) shows how to bring [Parquet](https://parquet.apache.org/) data sitting in S3 into an Amazon SageMaker Notebook and convert it into the recordIO-protobuf format that many SageMaker algorithms consume.\n",
    "- [Connecting to Redshift](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/working_with_redshift_data) demonstrates how to copy data from Redshift to S3 and vice-versa without leaving Amazon SageMaker Notebooks.\n",
    "- [Bring Your Own XGBoost Model](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/xgboost_bring_your_own_model) shows how to use Amazon SageMaker Algorithms containers to bring a pre-trained model to a realtime hosted endpoint without ever needing to think about REST APIs.\n",
    "- [Bring Your Own k-means Model](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/kmeans_bring_your_own_model) shows how to take a model that's been fit elsewhere and use Amazon SageMaker Algorithms containers to host it.\n",
    "- [Bring Your Own R Algorithm](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/r_bring_your_own) shows how to bring your own algorithm container to Amazon SageMaker using the R language.\n",
    "- [Installing the R Kernel](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/install_r_kernel) shows how to install the R kernel into an Amazon SageMaker Notebook Instance.\n",
    "- [Bring Your Own scikit Algorithm](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own) provides a detailed walkthrough on how to package a scikit learn algorithm for training and production-ready hosting.\n",
    "- [Bring Your Own MXNet Model](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/mxnet_mnist_byom) shows how to bring a model trained anywhere using MXNet into Amazon SageMaker.\n",
    "- [Bring Your Own TensorFlow Model](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/tensorflow_iris_byom) shows how to bring a model trained anywhere using TensorFlow into Amazon SageMaker.\n",
    "- [Inference Pipeline with SparkML and XGBoost](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/inference_pipeline_sparkml_xgboost_abalone) shows how to deploy an Inference Pipeline with SparkML for data pre-processing and XGBoost for training on the Abalone dataset. The pre-processing code is written once and used between training and inference.\n",
    "- [Inference Pipeline with SparkML and BlazingText](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/inference_pipeline_sparkml_blazingtext_dbpedia) shows how to deploy an Inference Pipeline with SparkML for data pre-processing and BlazingText for training on the DBPedia dataset. The pre-processing code is written once and used between training and inference.\n",
    "- [Experiment Management Capabilities with Search](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/search) shows how to organize Training Jobs into projects, and track relationships between Models, Endpoints, and Training Jobs.\n",
    "- [Host Multiple Models with Your Own Algorithm](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/multi_model_bring_your_own) shows how to deploy multiple models to a realtime hosted endpoint with your own custom algorithm.\n",
    "- [Host Multiple Models with XGBoost](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/multi_model_xgboost_home_value) shows how to deploy multiple models to a realtime hosted endpoint using a multi-model enabled XGBoost container.\n",
    "- [Host Multiple Models with SKLearn](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/multi_model_sklearn_home_value) shows how to deploy multiple models to a realtime hosted endpoint using a multi-model enabled SKLearn container.\n",
    "- [Using Amazon SageMaker inference pipelines with multi-model endpoints](https://github.com/aws/amazon-sagemaker-examples/blob/master/https://aws.amazon.com/blogs/machine-learning/using-amazon-sagemaker-inference-pipelines-with-multi-model-endpoints/?) shows you can deploy multiple models on a single multi-model enabled endpoint such that all models share the compute resources and the serving container. \n",
    "\n",
    "### Amazon SageMaker Neo Compilation Jobs\n",
    "\n",
    "These examples provide you an introduction to how to use Neo to optimizes deep learning model\n",
    "\n",
    "- [GluonCV SSD Mobilenet](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_neo_compilation_jobs/gluoncv_ssd_mobilenet) shows how to train gluoncv ssd mobilenet and use Amazon Sagemaker Neo to compile and optimize the trained model.\n",
    "- [Image Classification](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_neo_compilation_jobs/imageclassification_caltech) Adapts form [image classification](introduction_to_amazon_algorithms/imageclassification_caltech) including Neo API and comparsion between the baseline\n",
    "- [MNIST with MXNet](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_neo_compilation_jobs/mxnet_mnist) Adapts form [mxnet mnist](sagemaker-python-sdk/mxnet_mnist) including Neo API and comparsion between the baseline\n",
    "- [Deploying pre-trained PyTorch vision models](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_neo_compilation_jobs/pytorch_torchvision) shows how to use Amazon SageMaker Neo to compile and optimize pre-trained PyTorch models from TorchVision.\n",
    "- [Distributed TensorFlow](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_neo_compilation_jobs/tensorflow_distributed_mnist) Adapts form [tensorflow mnist](sagemaker-python-sdk/tensorflow_distributed_mnist) including Neo API and comparsion between the baseline\n",
    "- [Predicting Customer Churn](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_neo_compilation_jobs/xgboost_customer_churn) Adapts form [xgboost customer churn](https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/xgboost_customer_churn) including Neo API and comparsion between the baseline\n",
    "\n",
    "### Amazon SageMaker Procesing\n",
    "\n",
    "These examples show you how to use SageMaker Processing jobs to run data processing workloads.\n",
    "\n",
    "- [Scikit-Learn Data Processing and Model Evaluation](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_processing/scikit_learn_data_processing_and_model_evaluation) shows how to use SageMaker Processing and the Scikit-Learn container to run data preprocessing and model evaluation workloads.\n",
    "- [Feature transformation with Amazon SageMaker Processing and SparkML](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_processing/feature_transformation_with_sagemaker_processing) shows how to use SageMaker Processing to run data processing workloads using SparkML prior to training.\n",
    "- [Feature transformation with Amazon SageMaker Processing and Dask](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_processing/feature_transformation_with_sagemaker_processing_dask) shows how to use SageMaker Processing to transform data using Dask distributed clusters\n",
    "\n",
    "### Amazon SageMaker Pre-Built Framework Containers and the Python SDK\n",
    "\n",
    "#### Pre-Built Deep Learning Framework Containers\n",
    "\n",
    "These examples show you how to train and host in pre-built deep learning framework containers using the SageMaker Python SDK.\n",
    "\n",
    "- [Chainer CIFAR-10](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/chainer_cifar10) trains a VGG image classification network on CIFAR-10 using Chainer (both single machine and multi-machine versions are included)\n",
    "- [Chainer MNIST](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/chainer_mnist) trains a basic neural network on MNIST using Chainer (shows how to use local mode)\n",
    "- [Chainer sentiment analysis](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/chainer_sentiment_analysis) trains a LSTM network with embeddings to predict text sentiment using Chainer\n",
    "- [IRIS with Scikit-learn](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_iris) trains a Scikit-learn classifier on IRIS data\n",
    "- [MNIST with MXNet Gluon](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_gluon_mnist) trains a basic neural network on the MNIST handwritten digit dataset using MXNet Gluon\n",
    "- [MNIST with MXNet](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_mnist) trains a basic neural network on the MNIST handwritten digit data using MXNet's symbolic syntax\n",
    "- [Sentiment Analysis with MXNet Gluon](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_gluon_sentiment) trains a text classifier using embeddings with MXNet Gluon\n",
    "- [TensorFlow training and serving](sagemaker-python-sdk/tensorflow_script_mode_training_and_serving) trains a basic neural network on MNIST\n",
    "- [TensorFlow with Horovod](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_script_mode_horovod) trains on MNIST using Horovod for distributed training\n",
    "- [TensorFlow using shell commands](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_script_mode_using_shell_commands) shows how to use a shell script for the container's entry point\n",
    "\n",
    "#### Pre-Built Machine Learning Framework Containers\n",
    "\n",
    "These examples show you how to build Machine Learning models with frameworks like Apache Spark or Scikit-learn using SageMaker Python SDK.\n",
    "\n",
    "- [Inference with SparkML Serving](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/sparkml_serving_emr_mleap_abalone) shows how to build an ML model with Apache Spark using Amazon EMR on Abalone dataset and deploy in SageMaker with SageMaker SparkML Serving.\n",
    "- [Pipeline Inference with Scikit-learn and LinearLearner](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_inference_pipeline) builds a ML pipeline using Scikit-learn preprocessing and LinearLearner algorithm in single endpoint\n",
    "### Using Amazon SageMaker with Apache Spark\n",
    "\n",
    "These examples show how to use Amazon SageMaker for model training, hosting, and inference through Apache Spark using [SageMaker Spark](https://github.com/aws/sagemaker-spark). SageMaker Spark allows you to interleave Spark Pipeline stages with Pipeline stages that interact with Amazon SageMaker.\n",
    "\n",
    "- [MNIST with SageMaker PySpark](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-spark/pyspark_mnist)\n",
    "\n",
    "### AWS Marketplace\n",
    "\n",
    "#### Create algorithms/model packages for listing in AWS Marketplace for machine learning.\n",
    "\n",
    "This example shows you how to package a model-package/algorithm for listing in AWS Marketplace for machine learning.\n",
    "\n",
    "- [Creating Algorithm and Model Package - Listing on AWS Marketplace](https://github.com/aws/amazon-sagemaker-examples/blob/master/aws_marketplace/creating_marketplace_products) provides a detailed walkthrough on how to package a scikit learn algorithm to create SageMaker Algorithm and SageMaker Model Package entities that can be used with the enhanced SageMaker Train/Transform/Hosting/Tuning APIs and listed on AWS Marketplace.\n",
    "\n",
    "#### Use algorithms and model packages from AWS Marketplace for machine learning.\n",
    "\n",
    "These examples show you how to use model-packages and algorithms from AWS Marketplace for machine learning.\n",
    "\n",
    "- [Using Algorithms](https://github.com/aws/amazon-sagemaker-examples/blob/master/aws_marketplace/using_algorithms)\n",
    "\t- [Using Algorithm From AWS Marketplace](https://github.com/aws/amazon-sagemaker-examples/blob/master/aws_marketplace/using_algorithms/amazon_demo_product) provides a detailed walkthrough on how to use Algorithm with the enhanced SageMaker Train/Transform/Hosting/Tuning APIs by choosing a canonical product listed on AWS Marketplace.\n",
    "\t- [Using AutoML algorithm](https://github.com/aws/amazon-sagemaker-examples/blob/master/aws_marketplace/using_algorithms/automl) provides a detailed walkthrough on how to use AutoML algorithm from AWS Marketplace.\n",
    "\n",
    "- [Using Model Packages](https://github.com/aws/amazon-sagemaker-examples/blob/master/aws_marketplace/using_model_packages)\n",
    "\t- [Using Model Packages From AWS Marketplace](https://github.com/aws/amazon-sagemaker-examples/blob/master/aws_marketplace/using_model_packages/generic_sample_notebook) is a generic notebook which provides sample code snippets you can modify and use for performing inference on Model Packages from AWS Marketplace, using Amazon SageMaker.\n",
    "\t- [Using Amazon Demo product From AWS Marketplace](https://github.com/aws/amazon-sagemaker-examples/blob/master/aws_marketplace/using_model_packages/amazon_demo_product) provides a detailed walkthrough on how to use Model Package entities with the enhanced SageMaker Transform/Hosting APIs by choosing a canonical product listed on AWS Marketplace.\n",
    "\t- [Using models for extracting vehicle metadata](https://github.com/aws/amazon-sagemaker-examples/blob/master/aws_marketplace/using_model_packages/auto_insurance) provides a detailed walkthrough on how to use pre-trained models from AWS Marketplace for extracting metadata for a sample use-case of auto-insurance claim processing.\n",
    "\t- [Using models for identifying non-compliance at a workplace](https://github.com/aws/amazon-sagemaker-examples/blob/master/aws_marketplace/using_model_packages/improving_industrial_workplace_safety) provides a detailed walkthrough on how to use pre-trained models from AWS Marketplace for extracting metadata for a sample use-case of generating summary reports for identifying non-compliance at a construction/industrial workplace.\n",
    "\t- [Extracting insights from your credit card statements](https://github.com/aws/amazon-sagemaker-examples/blob/master/aws_marketplace/using_model_packages/financial_transaction_processing) provides a detailed walkthrough on how to use pre-trained models from AWS Marketplace for efficiently processing financial transaction logs.\n",
    "\n",
    "\n",
    "\n",
    "### Under Development\n",
    "\n",
    "These Amazon SageMaker examples fully illustrate a concept, but may require some additional configuration on the users part to complete.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "*What do I need in order to get started?*\n",
    "\n",
    "- The quickest setup to run example notebooks includes:\n",
    "  - An [AWS account](http://docs.aws.amazon.com/sagemaker/latest/dg/gs-account.html)\n",
    "  - Proper [IAM User and Role](http://docs.aws.amazon.com/sagemaker/latest/dg/authentication-and-access-control.html) setup\n",
    "  - An [Amazon SageMaker Notebook Instance](http://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html)\n",
    "  - An [S3 bucket](http://docs.aws.amazon.com/sagemaker/latest/dg/gs-config-permissions.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data into SageMaker \n",
    "\n",
    "- [Glue](https://aws.amazon.com/blogs/machine-learning/moving-from-notebooks-to-automated-ml-pipelines-using-amazon-sagemaker-and-aws-glue/)\n",
    "\n",
    "### Well Architected ML\n",
    "[Well Architected ML](https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf)\n",
    "\n",
    "[Analytics Lens - AWS WellArchitected Framework](https://docs.aws.amazon.com/wellarchitected/latest/analytics-lens/wellarchitected-analytics-lens.pdf#welcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
